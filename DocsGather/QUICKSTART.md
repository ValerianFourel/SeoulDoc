# Quick Start Guide - Naver Maps Hospital Scraper

## ğŸš€ Getting Started in 5 Minutes

### Step 1: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 2: Run Your First Scrape

#### Option A: Run the examples script (Recommended for beginners)
```bash
python examples.py
```
This will give you an interactive menu to choose from different example scenarios.

#### Option B: Quick test with a few locations
```bash
python naver_maps_scraper_improved.py
```
This will scrape hospitals in ëª…ë™, ì´íƒœì›ë™, and ê°•ë‚¨ì—­ areas.

### Step 3: View Your Results
The scraper will create two files:
- `naver_hospitals_YYYYMMDD_HHMMSS.json` - JSON format
- `naver_hospitals_YYYYMMDD_HHMMSS.csv` - Excel-compatible CSV

## ğŸ“Š Analyzing Your Data

After scraping, analyze your results:

```bash
python analyze_data.py naver_hospitals_YYYYMMDD_HHMMSS.json
```

This will show:
- Summary statistics
- Breakdown by category
- Results by location
- Rating analysis
- English-friendly facilities

## ğŸ¯ Common Use Cases

### Use Case 1: Find English-Speaking Hospitals in Popular Areas
```python
from naver_maps_scraper_improved import ImprovedNaverMapsScraper

locations = ['ì´íƒœì›ë™', 'í•œë‚¨ë™', 'ì—­ì‚¼ë™', 'ê°•ë‚¨ì—­']
queries = ['ì˜ì–´ ê°€ëŠ¥í•œ ë³‘ì›', 'ì™¸êµ­ì¸ í´ë¦¬ë‹‰']

with ImprovedNaverMapsScraper(headless=True, delay=2.5) as scraper:
    results = scraper.scrape_batch(queries, locations)
    scraper.save_to_json(results, 'english_hospitals.json')
```

### Use Case 2: Find 24-Hour Hospitals
```python
from naver_maps_scraper_improved import ImprovedNaverMapsScraper

locations = ['ê°•ë‚¨ì—­', 'ëª…ë™', 'ì¢…ë¡œ', 'ì‹ ì´Œë™']
queries = ['24ì‹œê°„ ë³‘ì›', 'ì‘ê¸‰ì‹¤']

with ImprovedNaverMapsScraper(headless=True, delay=2.5) as scraper:
    results = scraper.scrape_batch(queries, locations)
    scraper.save_to_csv(results, '24hour_hospitals.csv')
```

### Use Case 3: Find Specialists in Your Neighborhood
```python
from naver_maps_scraper_improved import ImprovedNaverMapsScraper

# Replace with your neighborhood
my_area = 'ì—°ë‚¨ë™'

specialties = [
    'ë‚´ê³¼',      # Internal medicine
    'ì¹˜ê³¼',      # Dental
    'í”¼ë¶€ê³¼',    # Dermatology
]

with ImprovedNaverMapsScraper(headless=False, delay=2.0) as scraper:
    results = scraper.scrape_batch(specialties, [my_area])
    scraper.save_to_json(results, f'{my_area}_specialists.json')
```

### Use Case 4: Scrape a Whole District
```python
from naver_maps_scraper_improved import scrape_full_district

# Scrape all hospitals in Gangnam-gu
scrape_full_district('ê°•ë‚¨êµ¬', 'ë³‘ì›')
```

## ğŸ” Search Query Reference

### General Facilities
- `ë³‘ì›` - Hospital (general)
- `ì˜ì›` - Clinic
- `ì¢…í•©ë³‘ì›` - General hospital
- `í´ë¦¬ë‹‰` - Clinic

### For Foreigners
- `ì˜ì–´ ê°€ëŠ¥í•œ ë³‘ì›` - English-speaking hospital
- `ì™¸êµ­ì¸ í´ë¦¬ë‹‰` - Foreigner clinic
- `êµ­ì œì§„ë£Œì„¼í„°` - International medical center

### Specialties
- `ë‚´ê³¼` - Internal medicine
- `ì™¸ê³¼` - Surgery
- `ì •í˜•ì™¸ê³¼` - Orthopedics
- `í”¼ë¶€ê³¼` - Dermatology
- `ì¹˜ê³¼` - Dental
- `ì•ˆê³¼` - Ophthalmology
- `ì´ë¹„ì¸í›„ê³¼` - ENT
- `ì‚°ë¶€ì¸ê³¼` - OB-GYN
- `ì†Œì•„ê³¼` - Pediatrics
- `ì •ì‹ ê³¼` - Psychiatry

### Service Types
- `24ì‹œê°„ ë³‘ì›` - 24-hour hospital
- `ì•¼ê°„ ì§„ë£Œ` - Evening care
- `ì£¼ë§ ì§„ë£Œ` - Weekend care
- `ì‘ê¸‰ì‹¤` - Emergency room

## âš™ï¸ Configuration Tips

### For Faster Scraping
```python
scraper = ImprovedNaverMapsScraper(
    headless=True,    # No browser window
    delay=1.5         # Shorter delay (be respectful!)
)
```

### For Debugging
```python
scraper = ImprovedNaverMapsScraper(
    headless=False,   # See what's happening
    delay=3.0         # Longer delay to watch
)
```

### For Maximum Results
```python
results = scraper.scrape_batch(
    queries=queries,
    locations=locations,
    max_results_per_search=100  # Get more results
)
```

## ğŸ“ Output Format

### JSON Output Example
```json
{
  "name": "ì„œìš¸ëŒ€í•™êµë³‘ì›",
  "category": "ì¢…í•©ë³‘ì›",
  "address": "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ëŒ€í•™ë¡œ 101",
  "phone": "02-2072-2114",
  "url": "https://map.naver.com/...",
  "rating": "4.5",
  "search_query": "ë³‘ì›",
  "search_location": "í˜œí™”ë™",
  "scraped_at": "2024-01-15T10:30:00"
}
```

### CSV Output
Opens directly in Excel with all the same fields in columns.

## ğŸ› ï¸ Troubleshooting

### "ChromeDriver not found"
â†’ The script will auto-download it. If it fails, check your internet connection.

### "No results found"
â†’ Try running with `headless=False` to see what's happening
â†’ Increase the delay: `delay=5.0`

### Timeout errors
â†’ Increase delay between requests
â†’ Check your internet connection

### Incomplete results
â†’ Increase `max_results_per_search`
â†’ Modify scroll iterations in the code

## ğŸ“ˆ Next Steps

1. **Start small**: Test with 2-3 locations first
2. **Review results**: Check the output files
3. **Analyze data**: Use `analyze_data.py` to understand your results
4. **Scale up**: Once working, scrape more locations
5. **Customize**: Modify the code for your specific needs

## ğŸ’¡ Pro Tips

1. **Batch by district**: Scrape one district at a time and save separately
2. **Use filters**: Search for specific types first, then general hospitals
3. **Check data quality**: Some results may have incomplete information
4. **Respect rate limits**: Use delays of at least 2 seconds
5. **Save incrementally**: For large jobs, save after each district

## ğŸ†˜ Need Help?

1. Check the README.md for detailed documentation
2. Look at examples.py for usage patterns
3. Run analyze_data.py to understand your data structure
4. Check debug HTML files if scraping fails

## â±ï¸ Time Estimates

- Single location: ~5-10 seconds
- 10 locations: ~1-2 minutes
- One district: ~5-10 minutes
- All Seoul: ~1-2 hours (with 2-3 second delays)

Happy scraping! ğŸ¥
